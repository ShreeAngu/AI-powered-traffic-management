# AI-Powered Adaptive Traffic Light System

A complete, runnable prototype demonstrating how reinforcement learning can outperform traditional fixed-time traffic signals. This system uses SUMO simulation with custom Gymnasium environments to train PPO and DQN agents for adaptive traffic control.

## ğŸš¦ Key Features

- **4-way Urban Intersection**: Realistic SUMO simulation with configurable traffic patterns
- **RL Agents**: PPO and DQN implementations using Stable-Baselines3
- **Baseline Comparison**: Fixed-time controller for performance benchmarking
- **Camera Perception**: Optional YOLOv8 vehicle detection from SUMO screenshots
- **Comprehensive Evaluation**: Performance metrics, visualizations, and statistical analysis
- **Interactive Demos**: Real-time visualization of different control strategies

## ğŸ¯ Performance Results

The RL agents typically achieve:
- **20-40% reduction** in total vehicle waiting time
- **15-25% improvement** in average vehicle speed
- **Better fairness** across traffic directions
- **Adaptive behavior** to varying traffic conditions

## ğŸš€ Quick Start

### Option 1: Automated Setup
```bash
# Clone the repository
git clone <repository-url>
cd ai-traffic-light-system

# Run automated setup
python setup.py

# Quick demonstration
python run_example.py demo
```

### Option 2: Manual Setup
```bash
# 1. Install SUMO
# Windows: Download from https://eclipse.dev/sumo/
# Linux: sudo apt-get install sumo sumo-tools
# macOS: brew install sumo

# 2. Install Python dependencies
pip install -r requirements.txt

# 3. Run quick test
python run_example.py demo
```

## ğŸ“Š Usage Examples

### Training RL Agents
```bash
# Train both PPO and DQN agents (50k timesteps each)
python src/train.py

# Monitor training progress
tensorboard --logdir results/tensorboard/
```

### Evaluating Performance
```bash
# Compare all models with baseline
python src/evaluate.py

# View detailed results
cat results/performance_comparison.csv
```

### Interactive Demonstrations
```bash
# Interactive demo menu
python src/demo.py

# Specific demonstrations
python src/demo.py fixed    # Fixed-time controller
python src/demo.py ppo      # PPO agent with GUI
python src/demo.py camera   # Camera-based perception
python src/demo.py compare  # Compare all methods
```

### Camera-Based Perception (Optional)
```bash
# Install YOLOv8 for vehicle detection
pip install ultralytics opencv-python

# Test camera perception
python src/camera_perception.py

# Run demo with camera input
python src/demo.py camera
```

## ğŸ“ Project Structure

```
ai-traffic-light-system/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ DOCUMENTATION.md             # Detailed technical docs
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ setup.py                    # Automated setup script
â”œâ”€â”€ run_example.py              # Quick examples and tests
â”‚
â”œâ”€â”€ sumo/                       # SUMO simulation files
â”‚   â”œâ”€â”€ intersection.net.xml        # Road network definition
â”‚   â”œâ”€â”€ intersection.rou.xml        # Traffic routes and flows
â”‚   â”œâ”€â”€ intersection.sumocfg        # SUMO configuration
â”‚   â””â”€â”€ gui-settings.cfg            # GUI visualization settings
â”‚
â”œâ”€â”€ src/                        # Python source code
â”‚   â”œâ”€â”€ traffic_env.py              # Gymnasium environment
â”‚   â”œâ”€â”€ train.py                   # RL agent training
â”‚   â”œâ”€â”€ evaluate.py                # Performance evaluation
â”‚   â”œâ”€â”€ demo.py                    # Interactive demonstrations
â”‚   â”œâ”€â”€ camera_perception.py       # YOLOv8 vehicle detection
â”‚   â””â”€â”€ utils.py                   # Utility functions
â”‚
â”œâ”€â”€ results/                    # Generated results (created during runs)
â”‚   â”œâ”€â”€ model_comparison.png        # Performance comparison plots
â”‚   â”œâ”€â”€ performance_comparison.csv  # Detailed metrics
â”‚   â””â”€â”€ detailed/                  # Individual model results
â”‚
â””â”€â”€ models/                     # Trained models (created during training)
    â”œâ”€â”€ ppo_traffic_final.zip      # Trained PPO agent
    â”œâ”€â”€ dqn_traffic_final.zip      # Trained DQN agent
    â””â”€â”€ best_model.zip             # Best performing model
```

## ğŸ”§ System Requirements

- **Python**: 3.10 or higher
- **SUMO**: 1.15.0 or higher
- **RAM**: 4GB minimum, 8GB recommended
- **Storage**: 2GB for full installation with models
- **OS**: Windows, Linux, or macOS

### Required Python Packages
- `sumo-tools` - SUMO Python interface
- `gymnasium` - RL environment framework
- `stable-baselines3` - RL algorithms
- `torch` - Deep learning backend
- `matplotlib`, `pandas`, `numpy` - Data analysis
- `seaborn` - Advanced plotting

### Optional Packages
- `ultralytics` - YOLOv8 for camera perception
- `opencv-python` - Image processing

## ğŸ® How It Works

### 1. Environment
- **Observation**: Number of halting vehicles in each direction [West, North, East, South]
- **Action**: Choose traffic light phase (North-South green OR East-West green)
- **Reward**: Negative total waiting time (encourages minimizing congestion)

### 2. Training Process
- Agents learn from 50,000+ simulation steps
- Experience replay and policy optimization
- Automatic hyperparameter tuning
- Performance tracking and model checkpointing

### 3. Evaluation
- Statistical comparison with fixed-time baseline
- Multiple performance metrics (waiting time, speed, throughput)
- Visualization of results and learning curves

## ğŸ”¬ Technical Details

### RL Algorithm Configuration
- **PPO**: Policy gradient method with clipping
- **DQN**: Deep Q-learning with experience replay
- **Network**: Multi-layer perceptron (64-64 hidden units)
- **Training**: 50k timesteps, evaluation every 2.5k steps

### Traffic Simulation
- **Intersection**: 4-way with 2 lanes per direction
- **Traffic Flow**: Realistic morning rush hour patterns
- **Vehicle Types**: Cars and trucks with different characteristics
- **Simulation Time**: 30-60 minutes per episode

### Performance Metrics
- **Primary**: Total waiting time, average speed
- **Secondary**: Throughput, queue fairness, phase switching frequency
- **Statistical**: Mean, standard deviation, confidence intervals

## ğŸ› ï¸ Customization

### Modify Traffic Patterns
Edit `sumo/intersection.rou.xml` to change vehicle flows:
```xml
<flow id="heavy_traffic" route="WE" begin="0" end="3600" vehsPerHour="1200"/>
```

### Adjust Reward Function
Modify `src/traffic_env.py` to change optimization objectives:
```python
def _calculate_reward(self):
    return -waiting_time - 0.1 * queue_variance + 0.05 * avg_speed
```

### Hyperparameter Tuning
Edit training parameters in `src/train.py` or create `config.json`

## ğŸ› Troubleshooting

### Common Issues
1. **"SUMO not found"**: Ensure SUMO is installed and in PATH
2. **"TraCI connection failed"**: Check if SUMO process is running
3. **Slow training**: Reduce simulation complexity or use GPU acceleration
4. **Memory errors**: Decrease buffer sizes or batch sizes

### Getting Help
- Check `DOCUMENTATION.md` for detailed technical information
- Run `python src/utils.py check` for system diagnostics
- Use `python run_example.py info` for installation verification

## ğŸ“ˆ Expected Results

After training, you should see:
- **Baseline (Fixed-time)**: ~2000-3000 total waiting time
- **PPO Agent**: ~1200-2000 total waiting time (20-40% improvement)
- **DQN Agent**: ~1400-2200 total waiting time (15-35% improvement)

Results vary based on traffic patterns and random initialization.

## ğŸ“ Educational Value

This project demonstrates:
- **Reinforcement Learning**: Practical RL application with real-world relevance
- **Simulation Integration**: SUMO + Python ecosystem integration
- **Performance Evaluation**: Statistical analysis and visualization
- **Computer Vision**: Optional YOLOv8 integration for perception
- **Software Engineering**: Modular, well-documented codebase

Perfect for:
- Machine learning students and researchers
- Traffic engineering applications
- RL algorithm development and testing
- Smart city technology demonstrations

## ğŸ“„ License

This project is provided as an educational prototype. Ensure compliance with local regulations before real-world deployment.

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:
- Multi-intersection coordination
- Advanced perception systems
- Real-world deployment considerations
- Additional RL algorithms
- Performance optimizations