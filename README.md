# ğŸš¦ AI-Powered Adaptive Traffic Light Control System

A complete reinforcement learning system that optimizes traffic flow using AI agents trained in SUMO simulation. This system demonstrates how machine learning can outperform traditional fixed-time traffic signals by adapting to real-time traffic conditions.

## ğŸ¯ **What This Project Does**

This system uses **Reinforcement Learning (RL)** to control traffic lights at a 4-way intersection. Instead of using fixed timing, the AI learns to optimize traffic flow by:

- **Observing** real-time traffic conditions (vehicle queues, waiting times)
- **Learning** optimal timing patterns through trial and error
- **Adapting** to different traffic densities and patterns
- **Reducing** overall waiting times by 15-30%

## ğŸ—ï¸ **System Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SUMO Traffic  â”‚â—„â”€â”€â–ºâ”‚  RL Environment  â”‚â—„â”€â”€â–ºâ”‚   AI Agent      â”‚
â”‚   Simulation    â”‚    â”‚  (Gymnasium)     â”‚    â”‚  (PPO/DQN)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²                        â–²                       â–²
         â”‚                        â”‚                       â”‚
         â–¼                        â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Interface â”‚    â”‚  Training Loop   â”‚    â”‚  Model Storage  â”‚
â”‚   (Real-time)   â”‚    â”‚  (Fast/Ultra)    â”‚    â”‚   (.zip files)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ **Quick Start**

### **Option 1: Web Interface (Recommended)**
```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Start the backend server
python ui_server.py

# 3. Start the UI server (in another terminal)
python serve_ui.py

# 4. Open browser to http://localhost:8080
```

### **Option 2: Command Line Interface**
```bash
# Ultra-fast training (1-2 minutes)
python ui_fast_train.py

# Quick training (3-8 minutes)  
python quick_train.py

# Production training (15-20 minutes)
python train_standalone.py
```

## ğŸ“‹ **Prerequisites**

### **Required Software:**
1. **Python 3.8+** with pip
2. **SUMO Traffic Simulator** 
   - Windows: Download from [eclipse.dev/sumo](https://eclipse.dev/sumo/)
   - Linux: `sudo apt-get install sumo sumo-tools`
   - macOS: `brew install sumo`

### **Python Dependencies:**
```bash
pip install -r requirements.txt
```
Installs: `stable-baselines3`, `gymnasium`, `torch`, `websockets`, `sumo-tools`, etc.

## ğŸ® **How to Use the System**

### **Web Interface Usage**

#### **1. Start the System**
```bash
# Terminal 1: Start WebSocket backend
python ui_server.py

# Terminal 2: Start HTTP server for UI
python serve_ui.py

# Browser: Open http://localhost:8080
```

#### **2. Web Interface Features**

**ğŸ›ï¸ Dashboard Tab:**
- **Real-time Metrics**: Vehicle count, wait times, efficiency
- **Traffic Visualization**: Interactive intersection with live vehicles
- **Performance Charts**: AI vs baseline comparison
- **Training Progress**: Live training monitoring with progress bars

**ğŸš¦ Simulation Tab:**
- **Control Modes**: 
  - *Manual*: Click buttons to control lights
  - *AI*: Let trained model control lights
  - *Fixed*: Traditional timed control
- **Traffic Density**: Adjust vehicle flow (600-2000 vehicles/hour)
- **Simulation Controls**: Start, pause, stop, reset

**ğŸ¤– AI Models Tab:**
- **Train Models**: Click "Train" button for PPO or DQN
- **Load Models**: Load pre-trained models
- **Model Status**: View training progress and performance
- **Quick Actions**: Run evaluation, deploy to production

**ğŸ“Š Analytics Tab:**
- **Performance History**: Historical traffic flow data
- **Vehicle Types**: Distribution of cars, trucks, buses
- **Wait Time Analysis**: Peak hours and efficiency trends

#### **3. Training a Model via Web Interface**
1. **Navigate** to "AI Models" tab
2. **Click "Train"** on PPO or DQN model card
3. **Watch Progress**: Real-time training updates (1-2 minutes)
4. **Auto-Load**: Model automatically loads when complete
5. **Test**: Switch to "Simulation" tab and select "AI" mode

#### **4. Loading Pre-Trained Models into UI**

**ğŸ“‚ Method 1: Load Models Trained via CLI**
```bash
# 1. Train model via command line
python ui_fast_train.py          # Creates: models/ppo_traffic_ui_fast.zip
python quick_train.py            # Creates: models/ppo_traffic_quick.zip  
python train_standalone.py      # Creates: models/ppo_traffic_final.zip

# 2. Start UI system
python ui_server.py             # Backend server
python serve_ui.py              # UI server (opens browser)

# 3. Load model in web interface:
#    - Go to "AI Models" tab
#    - Click "Load" button on PPO or DQN card
#    - Model automatically detects and loads from models/ directory
```

**ğŸ® Method 2: Load Models via Web Interface**
1. **Navigate** to "AI Models" tab in web interface
2. **Check Model Status**: 
   - Green "Ready" badge = Model loaded and ready
   - Gray "Not Loaded" badge = Model available but not loaded
   - Red "Missing" badge = No model file found
3. **Click "Load" Button** on desired model card (PPO or DQN)
4. **Wait for Confirmation**: Status changes to "Ready" when loaded
5. **Test Model**: Go to "Simulation" tab â†’ Select "AI" mode â†’ Start simulation

**ğŸ“ Method 3: Manual Model File Management**
```bash
# Check available models
ls models/
# Expected files:
# - ppo_traffic_final.zip      (Production PPO)
# - dqn_traffic_final.zip      (Production DQN)  
# - ppo_traffic_ui_fast.zip    (Ultra-fast PPO)
# - dqn_traffic_ui_fast.zip    (Ultra-fast DQN)

# Copy external models to project
cp /path/to/your/model.zip models/ppo_traffic_final.zip

# Restart UI server to detect new models
# Ctrl+C to stop, then restart:
python ui_server.py
```

**ğŸ”„ Method 4: Model Auto-Detection**
The UI automatically detects models in the `models/` directory with these naming patterns:
- `ppo_traffic_*.zip` â†’ Loads as PPO model
- `dqn_traffic_*.zip` â†’ Loads as DQN model
- `*_final.zip` â†’ Preferred for production use
- `*_ui_fast.zip` â†’ Ultra-fast trained models
- `*_quick.zip` â†’ Quick trained models

**âš ï¸ Troubleshooting Model Loading:**
```bash
# Issue: "Model not found"
# Solution: Check file exists and naming
ls models/ppo_traffic_final.zip

# Issue: "Failed to load model"  
# Solution: Ensure model was trained with same environment
python -c "
from stable_baselines3 import PPO
model = PPO.load('models/ppo_traffic_final.zip')
print('Model loaded successfully')
"

# Issue: Model loads but performs poorly
# Solution: Train longer or use production training
python train_standalone.py  # Select option 1 for best quality
```

**ğŸ“Š Model Performance in UI:**
Once loaded, you can see model performance in real-time:
- **Dashboard Tab**: Live efficiency metrics and performance charts
- **Simulation Tab**: Watch AI control traffic lights adaptively  
- **Analytics Tab**: Compare AI performance vs baseline control
- **Models Tab**: View model statistics and training history

### **Command Line Interface Usage**

#### **1. Ultra-Fast Training (1-2 minutes)**
```bash
python ui_fast_train.py

# Options:
# 1. UI Fast PPO (3K steps, ~1-2 min)
# 2. UI Fast DQN (2.5K steps, ~1-2 min)  
# 3. Both Models (~2-4 min total)
```

**Best for**: Quick testing, demonstrations, web UI integration

#### **2. Quick Training (3-8 minutes)**
```bash
python quick_train.py

# Options:
# 1. Quick PPO (50K steps, ~5-8 min)
# 2. Quick DQN (30K steps, ~3-5 min)
# 3. Both Models (~8-13 min total)
```

**Best for**: Development, testing, good quality models

#### **3. Production Training (15-20 minutes)**
```bash
python train_standalone.py

# Options:
# 1. Fast PPO (200K steps, ~15-20 min, 25-30% efficiency)
# 2. Fast DQN (150K steps, ~10-15 min, 20-25% efficiency)  
# 3. Ultra-Fast PPO (100K steps, ~5-10 min, 15-20% efficiency)
# 4. Both Fast (PPO + DQN, ~25-35 min)
```

**Best for**: Production deployment, maximum performance

## ğŸ§  **How the AI Works**

### **Reinforcement Learning Setup**

**ğŸ¯ State Space (What AI Observes):**
- Queue lengths in each direction (North, South, East, West)
- Current traffic light phase (0=NS Green, 1=EW Green)
- Time since last phase change
- Vehicle waiting times

**âš¡ Action Space (What AI Controls):**
- `0`: Keep current phase
- `1`: Switch to opposite phase (NS â†” EW)

**ğŸ† Reward Function (What AI Optimizes):**
```python
reward = -total_waiting_time - queue_penalty - switch_penalty
```
- **Negative waiting time**: Encourages reducing delays
- **Queue penalty**: Prevents long queues from forming
- **Switch penalty**: Prevents excessive light switching

### **Training Algorithms**

**ğŸš€ PPO (Proximal Policy Optimization):**
- **Type**: Policy gradient method
- **Strengths**: Stable, good for continuous control
- **Training Time**: 15-20 minutes for production quality
- **Performance**: 25-30% improvement over baseline

**âš¡ DQN (Deep Q-Network):**
- **Type**: Value-based method  
- **Strengths**: Sample efficient, good for discrete actions
- **Training Time**: 10-15 minutes for production quality
- **Performance**: 20-25% improvement over baseline

### **Training Process**
1. **Environment Reset**: Initialize SUMO simulation
2. **Episode Loop**: 
   - Agent observes traffic state
   - Agent selects action (keep/switch lights)
   - Environment executes action in SUMO
   - Environment returns reward and new state
3. **Learning**: Agent updates policy based on rewards
4. **Evaluation**: Test performance against baseline
5. **Model Saving**: Store trained model for deployment

## ğŸ“Š **Performance Results**

### **Typical Improvements Over Fixed-Time Control:**

| Metric | Baseline (Fixed) | AI Control | Improvement |
|--------|------------------|------------|-------------|
| **Average Wait Time** | 45-60 seconds | 30-40 seconds | **25-35% reduction** |
| **Total Throughput** | 800 vehicles/hour | 1000+ vehicles/hour | **20-25% increase** |
| **Queue Length** | 8-12 vehicles | 5-8 vehicles | **30-40% reduction** |
| **Fairness** | Uneven | Balanced | **Adaptive to demand** |

### **Training Speed Comparison:**

| Training Mode | Time | Steps | Quality | Use Case |
|--------------|------|-------|---------|----------|
| **UI Ultra-Fast** | 1-2 min | 2.5K-4K | Demo | Web interface |
| **Quick** | 3-8 min | 30K-50K | Good | Testing |
| **Fast** | 10-20 min | 100K-200K | High | Production |
| **Standard** | 2-4 hours | 500K+ | Highest | Research |

## ğŸ—‚ï¸ **Project Structure**

```
ai-traffic-light-system/
â”œâ”€â”€ ğŸ“ src/                     # Core Python modules
â”‚   â”œâ”€â”€ traffic_env.py          # RL environment (Gymnasium)
â”‚   â”œâ”€â”€ train.py               # Standard training script
â”‚   â”œâ”€â”€ evaluate.py            # Model evaluation
â”‚   â”œâ”€â”€ demo.py                # Interactive demo
â”‚   â””â”€â”€ utils.py               # Helper functions
â”œâ”€â”€ ğŸ“ ui/                      # Web interface
â”‚   â”œâ”€â”€ index.html             # Main UI page
â”‚   â”œâ”€â”€ script.js              # Frontend logic
â”‚   â””â”€â”€ styles.css             # UI styling
â”œâ”€â”€ ğŸ“ sumo/                    # SUMO simulation files
â”‚   â”œâ”€â”€ intersection.net.xml    # Road network
â”‚   â”œâ”€â”€ intersection.rou.xml    # Traffic routes
â”‚   â””â”€â”€ intersection.sumocfg    # SUMO configuration
â”œâ”€â”€ ğŸ“ models/                  # Trained AI models
â”‚   â”œâ”€â”€ ppo_traffic_final.zip   # Production PPO model
â”‚   â”œâ”€â”€ dqn_traffic_final.zip   # Production DQN model
â”‚   â”œâ”€â”€ ppo_traffic_ui_fast.zip # Ultra-fast PPO model
â”‚   â””â”€â”€ dqn_traffic_ui_fast.zip # Ultra-fast DQN model
â”œâ”€â”€ ğŸ“ results/                 # Training results
â”‚   â””â”€â”€ tensorboard/           # Training logs
â”œâ”€â”€ ğŸš€ ui_fast_train.py        # Ultra-fast training (1-2 min)
â”œâ”€â”€ ğŸš€ quick_train.py          # Quick training (3-8 min)
â”œâ”€â”€ ğŸš€ train_standalone.py     # Production training (15-20 min)
â”œâ”€â”€ ğŸŒ ui_server.py            # WebSocket backend server
â”œâ”€â”€ ğŸŒ serve_ui.py             # HTTP server for UI files
â”œâ”€â”€ ğŸ“‹ requirements.txt         # Python dependencies
â””â”€â”€ ğŸ“– README.md               # This file
```

## ï¿½ ***Model Management & Compatibility**

### **Model File Formats**
All models are saved as **Stable-Baselines3 ZIP files** containing:
- **Neural network weights** (PyTorch tensors)
- **Algorithm hyperparameters** (learning rate, network architecture)
- **Environment configuration** (observation/action spaces)
- **Training metadata** (steps, episodes, performance)

### **Model Naming Convention**
```
{algorithm}_{project}_{variant}.zip

Examples:
- ppo_traffic_final.zip      # Production PPO model
- dqn_traffic_final.zip      # Production DQN model  
- ppo_traffic_ui_fast.zip    # Ultra-fast PPO for UI
- dqn_traffic_quick.zip      # Quick DQN model
```

### **Model Compatibility**
**âœ… Compatible Models:**
- Trained with same environment (`TrafficLightEnv`)
- Same observation space (4 queue lengths + current phase)
- Same action space (0=keep, 1=switch)
- Stable-Baselines3 PPO or DQN algorithms

**âŒ Incompatible Models:**
- Different observation/action spaces
- Other RL libraries (Ray RLlib, TensorFlow Agents)
- Different environment configurations
- Corrupted or incomplete model files

### **Model Loading Priority**
The UI loads models in this order:
1. `*_final.zip` (production models)
2. `*_ui_fast.zip` (ultra-fast models)  
3. `*_quick.zip` (quick models)
4. Any other `ppo_traffic_*.zip` or `dqn_traffic_*.zip`

### **External Model Integration**
To use models trained elsewhere:
```bash
# 1. Ensure compatibility (same environment)
# 2. Copy to models directory with correct naming
cp external_ppo_model.zip models/ppo_traffic_final.zip

# 3. Verify model loads correctly
python -c "
from stable_baselines3 import PPO
from src.traffic_env import TrafficLightEnv

env = TrafficLightEnv(use_gui=False)
model = PPO.load('models/ppo_traffic_final.zip')
obs, _ = env.reset()
action, _ = model.predict(obs)
print(f'Model loaded successfully! Action: {action}')
env.close()
"

# 4. Restart UI server to detect new model
python ui_server.py
```

## ğŸ”§ **Configuration Options**

### **Training Parameters**
```python
# Ultra-Fast (UI) Configuration
PPO(
    learning_rate=1e-3,      # High for speed
    n_steps=256,             # Small buffer
    batch_size=64,           # Fast processing
    n_epochs=3,              # Quick updates
    net_arch=[64, 64]        # Small network
)

# Production Configuration  
PPO(
    learning_rate=5e-4,      # Balanced
    n_steps=1024,            # Larger buffer
    batch_size=128,          # Efficient processing
    n_epochs=8,              # Thorough updates
    net_arch=[128, 128]      # Larger network
)
```

### **Environment Settings**
```python
TrafficLightEnv(
    max_steps=300,           # Episode length (5 min simulation)
    yellow_time=3,           # Yellow light duration
    min_green_time=8,        # Minimum green time
    sumo_port=8813          # SUMO connection port
)
```

### **Traffic Density**
- **Light**: 600-800 vehicles/hour
- **Medium**: 1000-1400 vehicles/hour  
- **Heavy**: 1600-2000 vehicles/hour

## ğŸš¨ **Troubleshooting**

### **Common Issues:**

**âŒ "SUMO not found"**
```bash
# Windows: Add SUMO to PATH
set PATH=%PATH%;C:\Program Files (x86)\Eclipse\Sumo\bin

# Linux/Mac: Install SUMO
sudo apt-get install sumo sumo-tools  # Linux
brew install sumo                     # macOS
```

**âŒ "Port already in use"**
```bash
# Kill existing processes
tasklist | findstr sumo              # Windows
pkill -f sumo                        # Linux/Mac

# Use different ports
python serve_ui.py --port 8081
```

**âŒ "Training too slow"**
```bash
# Use ultra-fast training
python ui_fast_train.py              # 1-2 minutes

# Check GPU availability
python -c "import torch; print(torch.cuda.is_available())"
```

**âŒ "WebSocket connection failed"**
```bash
# Restart backend server
python ui_server.py

# Check firewall settings
# Ensure ports 8765 and 8080 are open
```

### **Performance Optimization:**

**ğŸš€ Speed Up Training:**
- Use GPU if available (`torch.cuda.is_available()`)
- Reduce episode length (`max_steps=200`)
- Use smaller networks (`net_arch=[32, 32]`)
- Increase learning rate (`learning_rate=1e-3`)

**ğŸ“ˆ Improve Quality:**
- Increase training steps (`total_timesteps=200000`)
- Use larger networks (`net_arch=[256, 256]`)
- Lower learning rate (`learning_rate=3e-4`)
- More training epochs (`n_epochs=10`)

## ğŸ¯ **Use Cases & Applications**

### **Research & Education:**
- **Traffic Engineering**: Study adaptive signal control
- **AI/ML Learning**: Hands-on reinforcement learning
- **Urban Planning**: Analyze intersection optimization
- **Simulation Studies**: Test different traffic scenarios

### **Real-World Applications:**
- **Smart City Pilots**: Deploy in test intersections
- **Traffic Optimization**: Reduce congestion in urban areas
- **Emergency Response**: Adaptive signals for emergency vehicles
- **Event Management**: Handle special event traffic flows

### **Development & Testing:**
- **Algorithm Comparison**: Test different RL algorithms
- **Hyperparameter Tuning**: Optimize training parameters
- **Scenario Testing**: Various traffic patterns and densities
- **Performance Benchmarking**: Compare against traditional systems

## ğŸ¤ **Contributing**

### **Development Setup:**
```bash
# Clone repository
git clone <repository-url>
cd ai-traffic-light-system

# Install development dependencies
pip install -r requirements.txt

# Run tests
python -m pytest tests/

# Start development servers
python ui_server.py          # Backend
python serve_ui.py           # Frontend
```

### **Adding New Features:**
1. **New Algorithms**: Add to `src/train.py`
2. **UI Components**: Modify `ui/` files
3. **Training Modes**: Create new training scripts
4. **Evaluation Metrics**: Extend `src/evaluate.py`

## ğŸ“„ **License**

This project is open source and available under the MIT License.

## ğŸ‰ **Getting Started Now**

**For Quick Demo:**
```bash
pip install -r requirements.txt
python ui_fast_train.py        # Train model (1-2 min)
python ui_server.py            # Start backend
python serve_ui.py             # Start UI (opens browser)
```

**For Production Use:**
```bash
pip install -r requirements.txt
python train_standalone.py     # Train production model (15-20 min)
python ui_server.py            # Deploy system
```

The system is designed to work out-of-the-box with minimal setup. The AI will learn to optimize traffic flow automatically, providing immediate improvements over traditional fixed-time signals! ğŸš€

## ğŸ“Š Usage Examples

### Training RL Agents
```bash
# Train both PPO and DQN agents (50k timesteps each)
python src/train.py

# Monitor training progress
tensorboard --logdir results/tensorboard/
```

### Evaluating Performance
```bash
# Compare all models with baseline
python src/evaluate.py

# View detailed results
cat results/performance_comparison.csv
```

### Interactive Demonstrations
```bash
# Interactive demo menu
python src/demo.py

# Specific demonstrations
python src/demo.py fixed    # Fixed-time controller
python src/demo.py ppo      # PPO agent with GUI
python src/demo.py camera   # Camera-based perception
python src/demo.py compare  # Compare all methods
```

### Camera-Based Perception (Optional)
```bash
# Install YOLOv8 for vehicle detection
pip install ultralytics opencv-python

# Test camera perception
python src/camera_perception.py

# Run demo with camera input
python src/demo.py camera
```

## ğŸ“ Project Structure

```
ai-traffic-light-system/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ DOCUMENTATION.md             # Detailed technical docs
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ setup.py                    # Automated setup script
â”œâ”€â”€ run_example.py              # Quick examples and tests
â”‚
â”œâ”€â”€ sumo/                       # SUMO simulation files
â”‚   â”œâ”€â”€ intersection.net.xml        # Road network definition
â”‚   â”œâ”€â”€ intersection.rou.xml        # Traffic routes and flows
â”‚   â”œâ”€â”€ intersection.sumocfg        # SUMO configuration
â”‚   â””â”€â”€ gui-settings.cfg            # GUI visualization settings
â”‚
â”œâ”€â”€ src/                        # Python source code
â”‚   â”œâ”€â”€ traffic_env.py              # Gymnasium environment
â”‚   â”œâ”€â”€ train.py                   # RL agent training
â”‚   â”œâ”€â”€ evaluate.py                # Performance evaluation
â”‚   â”œâ”€â”€ demo.py                    # Interactive demonstrations
â”‚   â”œâ”€â”€ camera_perception.py       # YOLOv8 vehicle detection
â”‚   â””â”€â”€ utils.py                   # Utility functions
â”‚
â”œâ”€â”€ results/                    # Generated results (created during runs)
â”‚   â”œâ”€â”€ model_comparison.png        # Performance comparison plots
â”‚   â”œâ”€â”€ performance_comparison.csv  # Detailed metrics
â”‚   â””â”€â”€ detailed/                  # Individual model results
â”‚
â””â”€â”€ models/                     # Trained models (created during training)
    â”œâ”€â”€ ppo_traffic_final.zip      # Trained PPO agent
    â”œâ”€â”€ dqn_traffic_final.zip      # Trained DQN agent
    â””â”€â”€ best_model.zip             # Best performing model
```

## ğŸ”§ System Requirements

- **Python**: 3.10 or higher
- **SUMO**: 1.15.0 or higher
- **RAM**: 4GB minimum, 8GB recommended
- **Storage**: 2GB for full installation with models
- **OS**: Windows, Linux, or macOS

### Required Python Packages
- `sumo-tools` - SUMO Python interface
- `gymnasium` - RL environment framework
- `stable-baselines3` - RL algorithms
- `torch` - Deep learning backend
- `matplotlib`, `pandas`, `numpy` - Data analysis
- `seaborn` - Advanced plotting

### Optional Packages
- `ultralytics` - YOLOv8 for camera perception
- `opencv-python` - Image processing

## ğŸ® How It Works

### 1. Environment
- **Observation**: Number of halting vehicles in each direction [West, North, East, South]
- **Action**: Choose traffic light phase (North-South green OR East-West green)
- **Reward**: Negative total waiting time (encourages minimizing congestion)

### 2. Training Process
- Agents learn from 50,000+ simulation steps
- Experience replay and policy optimization
- Automatic hyperparameter tuning
- Performance tracking and model checkpointing

### 3. Evaluation
- Statistical comparison with fixed-time baseline
- Multiple performance metrics (waiting time, speed, throughput)
- Visualization of results and learning curves

## ğŸ”¬ Technical Details

### RL Algorithm Configuration
- **PPO**: Policy gradient method with clipping
- **DQN**: Deep Q-learning with experience replay
- **Network**: Multi-layer perceptron (64-64 hidden units)
- **Training**: 50k timesteps, evaluation every 2.5k steps

### Traffic Simulation
- **Intersection**: 4-way with 2 lanes per direction
- **Traffic Flow**: Realistic morning rush hour patterns
- **Vehicle Types**: Cars and trucks with different characteristics
- **Simulation Time**: 30-60 minutes per episode

### Performance Metrics
- **Primary**: Total waiting time, average speed
- **Secondary**: Throughput, queue fairness, phase switching frequency
- **Statistical**: Mean, standard deviation, confidence intervals

## ğŸ› ï¸ Customization

### Modify Traffic Patterns
Edit `sumo/intersection.rou.xml` to change vehicle flows:
```xml
<flow id="heavy_traffic" route="WE" begin="0" end="3600" vehsPerHour="1200"/>
```

### Adjust Reward Function
Modify `src/traffic_env.py` to change optimization objectives:
```python
def _calculate_reward(self):
    return -waiting_time - 0.1 * queue_variance + 0.05 * avg_speed
```

### Hyperparameter Tuning
Edit training parameters in `src/train.py` or create `config.json`

## ğŸ› Troubleshooting

### Common Issues
1. **"SUMO not found"**: Ensure SUMO is installed and in PATH
2. **"TraCI connection failed"**: Check if SUMO process is running
3. **Slow training**: Reduce simulation complexity or use GPU acceleration
4. **Memory errors**: Decrease buffer sizes or batch sizes

### Getting Help
- Check `DOCUMENTATION.md` for detailed technical information
- Run `python src/utils.py check` for system diagnostics
- Use `python run_example.py info` for installation verification

## ğŸ“ˆ Expected Results

After training, you should see:
- **Baseline (Fixed-time)**: ~2000-3000 total waiting time
- **PPO Agent**: ~1200-2000 total waiting time (20-40% improvement)
- **DQN Agent**: ~1400-2200 total waiting time (15-35% improvement)

Results vary based on traffic patterns and random initialization.

## ğŸ“ Educational Value

This project demonstrates:
- **Reinforcement Learning**: Practical RL application with real-world relevance
- **Simulation Integration**: SUMO + Python ecosystem integration
- **Performance Evaluation**: Statistical analysis and visualization
- **Computer Vision**: Optional YOLOv8 integration for perception
- **Software Engineering**: Modular, well-documented codebase

Perfect for:
- Machine learning students and researchers
- Traffic engineering applications
- RL algorithm development and testing
- Smart city technology demonstrations

## ğŸ“„ License

This project is provided as an educational prototype. Ensure compliance with local regulations before real-world deployment.

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:
- Multi-intersection coordination
- Advanced perception systems
- Real-world deployment considerations
- Additional RL algorithms
- Performance optimizations